{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color: #f8f0fa;\n",
    "            border-left: 5px solid #1b4332;\n",
    "            font-family: 'Trebuchet MS', sans-serif;\n",
    "            border-right: 5px solid #1b4332;\n",
    "            padding: 12px;\n",
    "            border-radius: 50px 50px;\n",
    "            color: #1b4332;\n",
    "            text-align:center;\n",
    "            font-size:45px;\"><strong>Stop words</strong></h1>\n",
    "<hr style=\"border-top: 5px solid #264653;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Stop words are common words in a language (e.g., \"is,\" \"the,\" \"and\") that carry little semantic meaning and are often removed from text data during preprocessing in Natural Language Processing (NLP). Removing stop words helps reduce noise and improves the performance of NLP models.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Remove Stop Words?\n",
    "1. **Reduces Text Size**\n",
    "   - Removes frequent and uninformative words.\n",
    "2. **Improves Model Accuracy**\n",
    "   - Reduces noise and focuses on meaningful words.\n",
    "3. **Speeds Up Processing**\n",
    "   - Simplifies computations by reducing vocabulary size.\n",
    "\n",
    "---\n",
    "\n",
    "## Examples of Stop Words\n",
    "- Common English stop words: \"is,\" \"the,\" \"and,\" \"in,\" \"to\"\n",
    "- Language-specific stop words:\n",
    "  - French: \"le,\" \"la,\" \"et\"\n",
    "  - Arabic: \"و,\" \"في,\" \"من\"\n",
    "\n",
    "---\n",
    "\n",
    "## Popular Libraries for Handling Stop Words\n",
    "1. **NLTK**\n",
    "   - Provides built-in stop word lists for multiple languages.\n",
    "2. **spaCy**\n",
    "   - Includes customizable stop word sets.\n",
    "3. **Scikit-learn**\n",
    "   - Offers stop words for feature extraction.\n",
    "4. **Gensim**\n",
    "   - Provides stop word filtering for text analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## Implementation Examples\n",
    "\n",
    "### 1. Removing Stop Words with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hassa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['example', 'sentence', 'showing', 'removal', 'stop', 'words', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Load English stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "text = \"This is an example sentence showing the removal of stop words.\"\n",
    "words = word_tokenize(text)\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Removing Stop Words with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['example', 'sentence', 'showing', 'removal', 'stop', 'words', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"This is an example sentence showing the removal of stop words.\")\n",
    "filtered_tokens = [token.text for token in doc if not token.is_stop]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Removing Stop Words with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ENGLISH_STOP_WORDS\n\u001b[0;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is an example sentence showing the removal of stop words.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m words \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "text = \"This is an example sentence showing the removal of stop words.\"\n",
    "words = text.split()\n",
    "filtered_words = [word for word in words if word.lower() not in ENGLISH_STOP_WORDS]\n",
    "print(filtered_words) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Custom Stop Word List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['runn', 'car', 'car', 'swim']\n"
     ]
    }
   ],
   "source": [
    "custom_stop_words = [\"example\", \"showing\", \"is\", \"the\", \"of\"]\n",
    "text = \"This is an example sentence showing the removal of stop words.\"\n",
    "words = text.split()\n",
    "filtered_words = [word for word in words if word.lower() not in custom_stop_words]\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Challenges with Stop Words\n",
    "1. **Context Dependency**\n",
    "   - Words like \"not\" may be crucial in sentiment analysis.\n",
    "2. **Language-specific Stop Words**\n",
    "   - Requires different sets for different languages.\n",
    "3. **Domain-specific Needs**\n",
    "   - Generic stop word lists may not suit specialized domains.\n",
    "\n",
    "---\n",
    "\n",
    "## Customizing Stop Words\n",
    "1. **Adding New Stop Words**\n",
    "   - Enhance the list with domain-specific words.\n",
    "2. **Removing Crucial Words**\n",
    "   - Ensure important words are not mistakenly removed.\n",
    "\n",
    "Example in spaCy:\n",
    "```python\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.Defaults.stop_words.add(\"customword\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Applications of Stop Words Removal\n",
    "1. **Text Classification**\n",
    "   - Reduces noise for better feature extraction.\n",
    "2. **Search Engines**\n",
    "   - Filters out common words from queries.\n",
    "3. **Topic Modeling**\n",
    "   - Focuses on meaningful words for topic generation.\n",
    "4. **Sentiment Analysis**\n",
    "   - Helps focus on opinionated words.\n",
    "\n",
    "---\n",
    "\n",
    "## Alternatives to Stop Word Removal\n",
    "1. **Weighting Techniques**\n",
    "   - Use Term Frequency-Inverse Document Frequency (TF-IDF) to downweight common words instead of removing them.\n",
    "2. **Subword Tokenization**\n",
    "   - Focuses on meaningful subunits of words.\n",
    "\n",
    "---\n",
    "\n",
    "## Tips for Handling Stop Words\n",
    "1. Evaluate whether stop words removal is suitable for your NLP task.\n",
    "2. Customize stop word lists based on the domain and language.\n",
    "3. Combine stop word removal with other preprocessing steps like stemming or lemmatization.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "Stop word removal is a fundamental step in text preprocessing for NLP. While it simplifies data and improves model efficiency, it must be handled carefully to avoid losing critical information.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
