{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF in NLP \n",
    "\n",
    "Term Frequency-Inverse Document Frequency (TF-IDF) is a popular statistical measure used in Natural Language Processing (NLP) to evaluate the importance of a word in a document relative to a collection (corpus) of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. What is TF-IDF?**\n",
    "\n",
    "TF-IDF is a weighted representation of text that combines two metrics:\n",
    "- **Term Frequency (TF):** Measures how frequently a term occurs in a document.\n",
    "- **Inverse Document Frequency (IDF):** Measures how important a term is by evaluating how unique it is across the corpus.\n",
    "\n",
    "### **TF Formula**\n",
    "$$ \\text{TF}(t) = \\frac{f_t}{\\text{total terms in the document}} $$\n",
    "\n",
    "- $( f_t $): Frequency of term $( t $) in a document.\n",
    "- Total terms in the document: Total number of words in the document.\n",
    "\n",
    "### **IDF Formula**\n",
    "$$ \\text{IDF}(t) = \\log \\frac{N}{1 + \\text{df}(t)} $$\n",
    "\n",
    "- $( N $): Total number of documents in the corpus.\n",
    "- $ \\text{df}(t) $: Number of documents containing the term \\( t \\).\n",
    "\n",
    "### **TF-IDF Formula**\n",
    "$$ \\text{TF-IDF}(t) = \\text{TF}(t) \\times \\text{IDF}(t) $$\n",
    "\n",
    "This results in higher scores for words that are frequent in a specific document but rare across the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Why Use TF-IDF?**\n",
    "\n",
    "TF-IDF is widely used in text-based applications for its ability to:\n",
    "- Highlight important words in a document.\n",
    "- Reduce the weight of common words (e.g., \"the\", \"is\").\n",
    "- Provide a numerical representation of text for machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Implementing TF-IDF in Python**\n",
    "\n",
    "### **Step 1: Import Libraries and Create a Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "                Sentences\n",
      "0  The cat sat on the mat\n",
      "1  The dog lay on the rug\n",
      "2  The cat chased the dog\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    \"Sentences\": [\n",
    "        \"The cat sat on the mat\",\n",
    "        \"The dog lay on the rug\",\n",
    "        \"The cat chased the dog\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Dataset:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Apply TF-IDF Using `TfidfVectorizer`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n",
      "[[0.3564574  0.         0.         0.         0.46869865 0.3564574\n",
      "  0.         0.46869865 0.55364194]\n",
      " [0.         0.         0.3564574  0.46869865 0.         0.3564574\n",
      "  0.46869865 0.         0.55364194]\n",
      " [0.40352536 0.53058735 0.40352536 0.         0.         0.\n",
      "  0.         0.         0.62674687]]\n",
      "Vocabulary: ['cat' 'chased' 'dog' 'lay' 'mat' 'on' 'rug' 'sat' 'the']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(df['Sentences'])\n",
    "\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(tfidf_matrix.toarray())\n",
    "\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Convert TF-IDF Matrix into a DataFrame for Better Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TF-IDF matrix to a DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(\"TF-IDF DataFrame:\")\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Customizing TF-IDF**\n",
    "\n",
    "### **(a) Remove Stop Words**\n",
    "Stop words are common words (e.g., \"the\", \"is\") that do not carry significant meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary without Stop Words: ['cat' 'chased' 'dog' 'lay' 'mat' 'rug' 'sat']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df['Sentences'])\n",
    "print(\"Vocabulary without Stop Words:\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(b) Adjust Maximum and Minimum Document Frequency**\n",
    "Exclude rare and overly frequent terms by setting `max_df` and `min_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Vocabulary: ['cat' 'chased' 'dog' 'lay' 'mat' 'on' 'rug' 'sat']\n"
     ]
    }
   ],
   "source": [
    "# Adjust max_df and min_df\n",
    "vectorizer = TfidfVectorizer(max_df=0.7, min_df=0.1)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['Sentences'])\n",
    "print(\"Filtered Vocabulary:\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(c) Using N-Grams**\n",
    "Analyze combinations of consecutive words by specifying `ngram_range`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary with N-grams: ['cat' 'cat chased' 'cat sat' 'chased' 'chased the' 'dog' 'dog lay' 'lay'\n",
      " 'lay on' 'mat' 'on' 'on the' 'rug' 'sat' 'sat on' 'the' 'the cat'\n",
      " 'the dog' 'the mat' 'the rug']\n"
     ]
    }
   ],
   "source": [
    "# Use unigrams and bigrams\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "tfidf_matrix = vectorizer.fit_transform(df['Sentences'])\n",
    "print(\"Vocabulary with N-grams:\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb22ff5",
   "metadata": {},
   "source": [
    "## **Advantages of TF-IDF**\n",
    "1. **Simple and Effective:** \n",
    "   - TF-IDF is easy to implement and widely used in text mining and NLP applications.\n",
    "2. **Highlights Important Terms:** \n",
    "   - It assigns higher weights to important words while reducing the weights of common terms like stop words.\n",
    "3. **Noise Reduction:** \n",
    "   - Reduces the impact of words that appear frequently across all documents but carry little significance.\n",
    "4. **Sparse Representation:** \n",
    "   - Efficiently represents text as a sparse matrix, which can be processed by many machine learning algorithms.\n",
    "\n",
    "## **Disadvantages of TF-IDF**\n",
    "1. **Ignores Context:** \n",
    "   - TF-IDF does not consider the semantic meaning or word order, which can limit its effectiveness in understanding text.\n",
    "2. **Sensitive to Data Variability:** \n",
    "   - Rare terms or misrepresented terms can have disproportionately high weights, potentially skewing the results.\n",
    "3. **Computational Overhead:** \n",
    "   - Computing IDF for large corpora can be computationally expensive.\n",
    "4. **Vocabulary Dependency:** \n",
    "   - Relies heavily on preprocessing techniques like stemming and lemmatization to ensure consistency in vocabulary.\n",
    "\n",
    "## **Conclusion**\n",
    "TF-IDF is a foundational text representation technique in NLP that balances term frequency with term uniqueness. It is especially effective for tasks like:\n",
    "- Document similarity\n",
    "- Keyword extraction\n",
    "- Text classification\n",
    "\n",
    "However, TF-IDF has limitations in understanding context and relationships between words. For advanced NLP applications, more sophisticated techniques like **Word2Vec**, **GloVe**, or **transformer-based models** (e.g., BERT) are often preferred."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
