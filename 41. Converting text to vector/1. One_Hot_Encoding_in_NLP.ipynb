{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e5c322",
   "metadata": {},
   "source": [
    "# One-Hot Encoding in NLP \n",
    "\n",
    "One-Hot Encoding (OHE) is a popular technique to convert text or categorical data into a numerical format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **What is One-Hot Encoding?**\n",
    "\n",
    "One-Hot Encoding is a process of representing categorical data or text tokens as binary vectors.\n",
    "\n",
    "- Each unique word or token gets a unique index.\n",
    "- A word is represented as a vector where only the index corresponding to the word is 1, and the rest are 0.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "For the words `['cat', 'dog', 'mouse']`, the one-hot encoding would look like this:\n",
    "\n",
    "```\n",
    "cat -> [1, 0, 0]\n",
    "dog -> [0, 1, 0]\n",
    "mouse -> [0, 0, 1]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataset Example**\n",
    "\n",
    "Let's create a small dataset to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cat sat on the mat</td>\n",
       "      <td>Animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dogs are friendly animals</td>\n",
       "      <td>Animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The sun is bright today</td>\n",
       "      <td>Nature</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Sentence   Label\n",
       "0     The cat sat on the mat  Animal\n",
       "1  Dogs are friendly animals  Animal\n",
       "2    The sun is bright today  Nature"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Sentence\": [\n",
    "        \"The cat sat on the mat\",\n",
    "        \"Dogs are friendly animals\",\n",
    "        \"The sun is bright today\"\n",
    "    ],\n",
    "    \"Label\": [\"Animal\", \"Animal\", \"Nature\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hassa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cat sat on the mat</td>\n",
       "      <td>Animal</td>\n",
       "      <td>[The, cat, sat, on, the, mat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dogs are friendly animals</td>\n",
       "      <td>Animal</td>\n",
       "      <td>[Dogs, are, friendly, animals]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The sun is bright today</td>\n",
       "      <td>Nature</td>\n",
       "      <td>[The, sun, is, bright, today]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Sentence   Label                          Tokens\n",
       "0     The cat sat on the mat  Animal   [The, cat, sat, on, the, mat]\n",
       "1  Dogs are friendly animals  Animal  [Dogs, are, friendly, animals]\n",
       "2    The sun is bright today  Nature   [The, sun, is, bright, today]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenize the sentences\n",
    "df['Tokens'] = df['Sentence'].apply(word_tokenize)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Labels: ['Animal' 'Animal' 'Nature']\n",
      "One-Hot Encoded Labels:\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "labels = df['Label'].values.reshape(-1, 1)\n",
    "labels_encoded = encoder.fit_transform(labels)\n",
    "\n",
    "print(\"Original Labels:\", df['Label'].values)\n",
    "print(\"One-Hot Encoded Labels:\")\n",
    "print(labels_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb952666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [The, cat, sat, on, the, mat]\n",
       "1    [Dogs, are, friendly, animals]\n",
       "2     [The, sun, is, bright, today]\n",
       "Name: Tokens, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8810eb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'cat',\n",
       " 'sat',\n",
       " 'on',\n",
       " 'the',\n",
       " 'mat',\n",
       " 'Dogs',\n",
       " 'are',\n",
       " 'friendly',\n",
       " 'animals',\n",
       " 'The',\n",
       " 'sun',\n",
       " 'is',\n",
       " 'bright',\n",
       " 'today']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Words = [token for sublist in df['Tokens'] for token in sublist]\n",
    "Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ffeac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Words = np.array(Words).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "581ec7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoded Sentence:\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "Words_encoded = encoder.fit_transform(Words)\n",
    "\n",
    "print(\"One-Hot Encoded Sentence:\")\n",
    "print(Words_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a786a7",
   "metadata": {},
   "source": [
    "## **Advantages**\n",
    "1. **Simplicity**: \n",
    "   - One-Hot Encoding is easy to implement and understand.\n",
    "2. **No Assumptions**: \n",
    "   - It does not impose any assumptions about relationships between categories.\n",
    "3. **Effective for Small Vocabularies**: \n",
    "   - Works well when the vocabulary size is small.\n",
    "4. **Input for ML Models**: \n",
    "   - Provides a straightforward way to represent categorical data for machine learning models.\n",
    "   \n",
    "## **Disadvantages**\n",
    "1. **High Dimensionality**: \n",
    "   - For large vocabularies, the representation becomes sparse, consuming significant memory and computational resources.\n",
    "2. **Lack of Semantic Meaning**: \n",
    "   - Does not capture relationships or similarities between words (e.g., \"king\" and \"queen\" are equally dissimilar to \"apple\").\n",
    "3. **Scalability Issues**: \n",
    "   - Not practical for tasks with massive vocabularies (e.g., large corpora or multi-lingual datasets).\n",
    "4. **Curse of Dimensionality**: \n",
    "   - High-dimensional feature spaces can lead to overfitting in machine learning models.\n",
    "5. **No Context Awareness**: \n",
    "   - It treats words independently, ignoring the context in which they appear.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "In this tutorial, we learned:\n",
    "- How to tokenize text data.\n",
    "- How to apply one-hot encoding to words using `CountVectorizer`.\n",
    "- How to apply one-hot encoding to labels using `OneHotEncoder`.\n",
    "- How to combine these features into a unified matrix.\n",
    "\n",
    "One-Hot Encoding is simple but effective for basic NLP tasks. For more advanced tasks, consider using embeddings like Word2Vec, GloVe, or contextual embeddings like BERT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
