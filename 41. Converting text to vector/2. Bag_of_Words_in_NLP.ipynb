{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words (BoW) in NLP \n",
    "\n",
    "The **Bag of Words (BoW)** model is one of the simplest and most effective methods for text representation in NLP. \n",
    "This notebook will guide you through its concept, implementation, customization, advantages, and limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. What is Bag of Words?**\n",
    "\n",
    "The **Bag of Words** model represents text as a collection of unique words and their corresponding frequencies in a document or corpus, ignoring grammar, order, or structure.\n",
    "\n",
    "### **How It Works:**\n",
    "1. Tokenize the text into words.\n",
    "2. Create a vocabulary of all unique words.\n",
    "3. Represent each document as a vector where each element corresponds to the frequency of a word in the document.\n",
    "\n",
    "### **Example:**\n",
    "\n",
    "For two sentences:\n",
    "- Sentence 1: \"The cat sat on the mat\"\n",
    "- Sentence 2: \"The dog lay on the rug\"\n",
    "\n",
    "Vocabulary: `['The', 'cat', 'sat', 'on', 'the', 'mat', 'dog', 'lay', 'rug']`\n",
    "\n",
    "BoW representation:\n",
    "- Sentence 1: `[2, 1, 1, 1, 0, 1, 0, 0, 0]`\n",
    "- Sentence 2: `[2, 0, 0, 1, 0, 0, 1, 1, 1]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Why Use Bag of Words?**\n",
    "\n",
    "BoW is simple yet powerful for tasks like:\n",
    "- Text classification\n",
    "- Sentiment analysis\n",
    "- Information retrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Implementing Bag of Words in Python**\n",
    "\n",
    "### **Step 1: Import Libraries and Create a Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "                Sentences\n",
      "0  The cat sat on the mat\n",
      "1  The dog lay on the rug\n",
      "2  The cat chased the dog\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    \"Sentences\": [\n",
    "        \"The cat sat on the mat\",\n",
    "        \"The dog lay on the rug\",\n",
    "        \"The cat chased the dog\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Dataset:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Tokenize and Vectorize Using `CountVectorizer`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['cat' 'chased' 'dog' 'lay' 'mat' 'on' 'rug' 'sat' 'the']\n",
      "BoW Representation:\n",
      "[[1 0 0 0 1 1 0 1 2]\n",
      " [0 0 1 1 0 1 1 0 2]\n",
      " [1 1 1 0 0 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(df['Sentences'])\n",
    "\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"BoW Representation:\")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Convert BoW into a DataFrame for Better Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words DataFrame:\n",
      "   cat  chased  dog  lay  mat  on  rug  sat  the\n",
      "0    1       0    0    0    1   1    0    1    2\n",
      "1    0       0    1    1    0   1    1    0    2\n",
      "2    1       1    1    0    0   0    0    0    2\n"
     ]
    }
   ],
   "source": [
    "# Convert BoW to a DataFrame\n",
    "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(\"Bag of Words DataFrame:\")\n",
    "print(bow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Customizing Bag of Words**\n",
    "\n",
    "You can customize `CountVectorizer` to suit specific needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(a) Removing Stop Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary without Stop Words: ['cat' 'chased' 'dog' 'lay' 'mat' 'rug' 'sat']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['Sentences'])\n",
    "print(\"Vocabulary without Stop Words:\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(b) Limiting Vocabulary Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Vocabulary: ['cat' 'dog' 'lay' 'on' 'the']\n"
     ]
    }
   ],
   "source": [
    "# Limit vocabulary size to top 5 words\n",
    "vectorizer = CountVectorizer(max_features=5)\n",
    "X = vectorizer.fit_transform(df['Sentences'])\n",
    "print(\"Top 5 Vocabulary:\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **(c) Using N-grams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary with N-grams: ['cat' 'cat chased' 'cat sat' 'chased' 'chased the' 'dog' 'dog lay' 'lay'\n",
      " 'lay on' 'mat' 'on' 'on the' 'rug' 'sat' 'sat on' 'the' 'the cat'\n",
      " 'the dog' 'the mat' 'the rug']\n"
     ]
    }
   ],
   "source": [
    "# Use unigrams and bigrams\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(df['Sentences'])\n",
    "print(\"Vocabulary with N-grams:\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Advantages of Bag of Words**\n",
    "\n",
    "1. **Simplicity**: Easy to implement and understand.\n",
    "2. **Good for Text Classification**: Works well with algorithms like Naive Bayes, Logistic Regression, and SVM.\n",
    "3. **Sparse Representation**: Efficient for small datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Limitations of Bag of Words**\n",
    "\n",
    "1. **Ignores Context**: Fails to capture relationships between words (e.g., \"not happy\" and \"happy\" are treated separately).\n",
    "2. **High Dimensionality**: For large vocabularies, the feature space becomes very large.\n",
    "3. **Sensitive to Vocabulary**: Depends heavily on preprocessing (e.g., removing stop words).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Conclusion**\n",
    "\n",
    "The **Bag of Words** model is a simple yet effective way to represent text data for many NLP tasks. \n",
    "While it has its limitations, it can be improved by combining it with techniques like TF-IDF or word embeddings for better performance in advanced applications.\n",
    "\n",
    "### **Next Steps:**\n",
    "- Experiment with preprocessing techniques like stemming and lemmatization.\n",
    "- Combine BoW with Term Frequency-Inverse Document Frequency (TF-IDF) for weighting important words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
