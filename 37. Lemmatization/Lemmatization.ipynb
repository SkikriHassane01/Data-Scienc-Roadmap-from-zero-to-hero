{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color: #f8f0fa;\n",
    "            border-left: 5px solid #1b4332;\n",
    "            font-family: 'Trebuchet MS', sans-serif;\n",
    "            border-right: 5px solid #1b4332;\n",
    "            padding: 12px;\n",
    "            border-radius: 50px 50px;\n",
    "            color: #1b4332;\n",
    "            text-align:center;\n",
    "            font-size:45px;\"><strong>Lemmatization</strong></h1>\n",
    "<hr style=\"border-top: 5px solid #264653;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Lemmatization is a text normalization technique in Natural Language Processing (NLP) that reduces words to their base or dictionary form, known as a \"lemma.\" Unlike stemming, lemmatization considers the context and grammar of the word, resulting in meaningful root forms.\n",
    "\n",
    "---\n",
    "\n",
    "## Why is Lemmatization Important?\n",
    "1. **Context-aware Normalization**\n",
    "   - Ensures words are reduced to valid dictionary words.\n",
    "   - Example: \"better\" → \"good\" (context-aware).\n",
    "\n",
    "2. **Improves Model Accuracy**\n",
    "   - Retains the semantic meaning of text while reducing variations.\n",
    "\n",
    "3. **Facilitates Language Analysis**\n",
    "   - Useful in linguistic studies, machine translation, and sentiment analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## How Does Lemmatization Work?\n",
    "Lemmatization involves analyzing the morphological structure of words and reducing them to their lemma based on Part-of-Speech (POS) tags. For example:\n",
    "- Words: \"running,\" \"ran,\" \"runs\" → Lemma: \"run\"\n",
    "- Words: \"better,\" \"best\" → Lemma: \"good\"\n",
    "\n",
    "---\n",
    "\n",
    "## Libraries Supporting Lemmatization\n",
    "1. **NLTK (WordNet Lemmatizer)**\n",
    "   - Uses WordNet database to lemmatize words based on POS tags.\n",
    "\n",
    "2. **spaCy**\n",
    "   - Efficient lemmatizer with support for multiple languages.\n",
    "\n",
    "3. **TextBlob**\n",
    "   - Simple lemmatization interface using NLTK.\n",
    "\n",
    "4. **Stanford CoreNLP**\n",
    "   - Advanced lemmatization with deep linguistic analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## Implementation Examples\n",
    "\n",
    "### 1. Lemmatization with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hassa\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we need to download wordnet\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'run', 'run', 'do', 'meet']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = ['running', 'ran', 'runs', 'doing', 'meeting']\n",
    "\n",
    "\"\"\" POS tag:\n",
    "Noun => N\n",
    "Verb => v\n",
    "Adjective => a\n",
    "adverb => r\n",
    "\"\"\"\n",
    "lemmas = [lemmatizer.lemmatize(word, pos=\"v\") for word in words]\n",
    "\n",
    "print(lemmas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lemmatization with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'striped', 'bat', 'be', 'hang', 'on', 'their', 'foot', 'for', 'good', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"The striped bats are hanging on their feet for best.\")\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Lemmatization with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'run', 'run', 'best']\n"
     ]
    }
   ],
   "source": [
    "from textblob import Word\n",
    "\n",
    "words = [\"running\", \"ran\", \"runs\", \"best\"]\n",
    "lemmas = [Word(word).lemmatize(\"v\") for word in words]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Advantages of Lemmatization\n",
    "1. **Context Sensitivity**\n",
    "   - Reduces words accurately based on their POS and semantics.\n",
    "2. **Improves NLP Model Interpretability**\n",
    "   - Retains meaningful root forms.\n",
    "3. **Language-specific Rules**\n",
    "   - Handles grammar and morphology of different languages effectively.\n",
    "\n",
    "---\n",
    "\n",
    "## Challenges of Lemmatization\n",
    "1. **Computationally Expensive**\n",
    "   - Requires linguistic analysis for accurate results.\n",
    "2. **Dependency on POS Tags**\n",
    "   - Errors in POS tagging can lead to incorrect lemmatization.\n",
    "3. **Language-specific Rules**\n",
    "   - Each language requires custom lemmatization rules.\n",
    "\n",
    "---\n",
    "\n",
    "## Applications of Lemmatization\n",
    "1. **Search Engines**\n",
    "   - Enhances query matching and document retrieval accuracy.\n",
    "2. **Chatbots and Virtual Assistants**\n",
    "   - Normalizes user queries for better intent matching.\n",
    "3. **Machine Translation**\n",
    "   - Simplifies word variations for effective translation.\n",
    "4. **Text Summarization**\n",
    "   - Groups similar words under the same lemma.\n",
    "\n",
    "---\n",
    "\n",
    "## Tips for Effective Lemmatization\n",
    "1. Use high-quality POS tagging to improve lemmatization accuracy.\n",
    "2. Combine lemmatization with other preprocessing steps like stopword removal.\n",
    "3. Choose the appropriate library based on the language and application requirements.\n",
    "\n",
    "---\n",
    "\n",
    "## Comparison: Stemming vs Lemmatization\n",
    "\n",
    "| Feature            | Stemming                   | Lemmatization               |\n",
    "|---------------------|----------------------------|-----------------------------|\n",
    "| Output             | Stem (may not be a word)   | Valid dictionary word       |\n",
    "| Context Sensitivity | No                         | Yes                         |\n",
    "| Accuracy           | Lower                      | Higher                      |\n",
    "| Speed              | Faster                     | Slower                      |\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "Lemmatization is an essential technique for context-aware text normalization in NLP. By reducing words to their dictionary forms, it enhances the semantic understanding and accuracy of NLP models.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
