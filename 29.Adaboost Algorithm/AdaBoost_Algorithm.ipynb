{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b0f614",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color: #f8f0fa;\n",
    "            border-left: 5px solid #1b4332;\n",
    "            font-family: 'Trebuchet MS', sans-serif;\n",
    "            border-right: 5px solid #1b4332;\n",
    "            padding: 12px;\n",
    "            border-radius: 50px 50px;\n",
    "            color: #1b4332;\n",
    "            text-align:center;\n",
    "            font-size:45px;\"><strong>ðŸ˜ŠAdaBoost Algorithm from ScratchðŸŒŸ</strong></h1>\n",
    "<hr style=\"border-top: 5px solid #264653;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0327ab",
   "metadata": {},
   "source": [
    "This notebook provides a step-by-step explanation and implementation of the **AdaBoost algorithm** using Python. \n",
    "Weâ€™ll go through the algorithm, building it from scratch, with a simple example to clarify the concepts of \n",
    "decision stumps, weighted errors, weight updates, and the final classifier. \n",
    "\n",
    "AdaBoost, or **Adaptive Boosting**, is an ensemble learning method that combines multiple weak classifiers \n",
    "to form a strong classifier. In this example, we use **decision stumps** (simple decision rules) as the weak classifiers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9e58f",
   "metadata": {},
   "source": [
    "\n",
    "## AdaBoost Algorithm Steps\n",
    "\n",
    "Hereâ€™s a step-by-step guide on how the AdaBoost algorithm works:\n",
    "\n",
    "1. **Initialize Weights**: Start by assigning equal weights to all training samples.\n",
    "\n",
    "2. **Train Weak Classifiers**: For each weak classifier (e.g., decision stump), calculate the weighted error.\n",
    "\n",
    "3. **Calculate Error for Each Weak Classifier**: For each classifier $( h_t $), calculate the weighted error \n",
    "based on misclassified samples.\n",
    "\n",
    "4. **Calculate Classifier Weight**: The classifierâ€™s weight depends on its error rate. A more accurate classifier \n",
    "receives a higher weight.\n",
    "\n",
    "5. **Update Sample Weights**: Increase the weights of misclassified samples, emphasizing challenging samples in \n",
    "subsequent rounds.\n",
    "\n",
    "6. **Final Classifier**: Combine all weak classifiers using their weights to form the final strong classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef72bf6a",
   "metadata": {},
   "source": [
    "\n",
    "## Example Dataset\n",
    "\n",
    "A dataset with **10 samples** and **4 features** will be used to illustrate AdaBoost.\n",
    "\n",
    "| Sample | Feature 1 | Feature 2 | Feature 3 | Feature 4 | Label |\n",
    "|--------|-----------|-----------|-----------|-----------|-------|\n",
    "| 1      | 1         | 2         | 1         | 3         | +1    |\n",
    "| 2      | 2         | 1         | 3         | 1         | -1    |\n",
    "| 3      | 1         | 1         | 2         | 2         | +1    |\n",
    "| 4      | 2         | 2         | 1         | 3         | -1    |\n",
    "| 5      | 1         | 3         | 1         | 1         | +1    |\n",
    "| 6      | 3         | 1         | 2         | 2         | -1    |\n",
    "| 7      | 2         | 3         | 3         | 1         | +1    |\n",
    "| 8      | 3         | 2         | 1         | 2         | -1    |\n",
    "| 9      | 1         | 2         | 3         | 3         | +1    |\n",
    "| 10     | 2         | 1         | 2         | 3         | -1    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3261f127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature_1  Feature_2  Feature_3  Feature_4  Label\n",
       "Sample                                                   \n",
       "1               1          2          1          3      1\n",
       "2               2          1          3          1     -1\n",
       "3               1          1          2          2      1\n",
       "4               2          2          1          3     -1\n",
       "5               1          3          1          1      1\n",
       "6               3          1          2          2     -1\n",
       "7               2          3          3          1      1\n",
       "8               3          2          1          2     -1\n",
       "9               1          2          3          3      1\n",
       "10              2          1          2          3     -1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create the dataset\n",
    "data = {\n",
    "    'Sample': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Feature_1': [1, 2, 1, 2, 1, 3, 2, 3, 1, 2],\n",
    "    'Feature_2': [2, 1, 1, 2, 3, 1, 3, 2, 2, 1],\n",
    "    'Feature_3': [1, 3, 2, 1, 1, 2, 3, 1, 3, 2],\n",
    "    'Feature_4': [3, 1, 2, 3, 1, 2, 1, 2, 3, 3],\n",
    "    'Label': [1, -1, 1, -1, 1, -1, 1, -1, 1, -1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('Sample', inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e64526a",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1: Initialize Weights\n",
    "\n",
    "With 10 samples, each starts with a weight of $( \\frac{1}{10} = 0.1 $).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7645c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialize weights equally\n",
    "n_samples = len(df)\n",
    "weights = np.full(n_samples, 1 / n_samples)\n",
    "weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f2803",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Train a Weak Classifier (Decision Stump)\n",
    "\n",
    "A decision stump is a simple rule like \"If Feature 1 = 1, predict +1; else -1.\"\n",
    "We'll generate decision stumps for each feature and calculate their performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55f98b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.1), (2, 0.7), (3, 0.5), (4, 0.4)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define function to calculate weighted error\n",
    "def weighted_error(predictions, weights, true_labels):\n",
    "    return np.sum(weights[predictions != true_labels])\n",
    "\n",
    "X = df[['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4']].values\n",
    "y = df['Label'].values\n",
    "\n",
    "errors = []\n",
    "for feature_idx in range(X.shape[1]):\n",
    "    predictions = np.where(X[:, feature_idx] == 1, 1, -1)\n",
    "    error = weighted_error(predictions, weights, y)\n",
    "    errors.append((feature_idx + 1, error))\n",
    "errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe46993",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Select the Best Classifier Based on Weighted Error\n",
    "\n",
    "The decision stump with the lowest error is selected as the weak classifier for this round.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0a6110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Select the best classifier based on minimum error\n",
    "best_stump = min(errors, key=lambda x: x[1])\n",
    "best_stump\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823d1309",
   "metadata": {},
   "source": [
    "remember here the only error is the sample 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd371e7",
   "metadata": {},
   "source": [
    "\n",
    "## Step 4: Calculate Classifier Weight\n",
    "\n",
    "The weight $( \\alpha_t $) of each classifier depends on its error rate:\n",
    "\n",
    "$$\n",
    "\\alpha_t = \\frac{1}{2} \\ln \\left( \\frac{1 - \\text{Error}}{\\text{Error}} \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d49f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0986122886681098"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Calculate classifier weight\n",
    "best_error = best_stump[1]\n",
    "alpha = 0.5 * np.log((1 - best_error) / best_error) if best_error > 0 else 1e10\n",
    "alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf6ec8",
   "metadata": {},
   "source": [
    "\n",
    "## Step 5: Update Sample Weights\n",
    "\n",
    "Increase weights for misclassified samples to give them more importance in the next round.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d98ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08333333, 0.08333333, 0.08333333, 0.08333333, 0.08333333,\n",
       "       0.08333333, 0.25      , 0.08333333, 0.08333333, 0.08333333])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "feature_idx = best_stump[0] - 1  # Convert to 0-indexed\n",
    "predictions = np.where(X[:, feature_idx] == 1, 1, -1)\n",
    "\n",
    "# Update weights\n",
    "weights *= np.exp(alpha * (predictions != y))\n",
    "weights /= np.sum(weights)  # Normalize\n",
    "weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e1dff6",
   "metadata": {},
   "source": [
    "we can see here that the sample 7 has a bigger change to be selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4301c158",
   "metadata": {},
   "source": [
    "\n",
    "## Step 6: Combine Weak Classifiers\n",
    "\n",
    "We combine the weak classifiers to form the final model by weighting their predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5424e",
   "metadata": {},
   "source": [
    "\n",
    "## Step 7: Test the Final Model\n",
    "\n",
    "Using the final model, we predict on new data to evaluate performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06abfe3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, 2],\n",
       "       [1, 3, 1, 1],\n",
       "       [3, 1, 3, 2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Example test data\n",
    "test_data = np.array([[2, 2, 2, 2], [1, 3, 1, 1], [3, 1, 3, 2]])\n",
    "test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0986c023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1., -1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = np.sign(np.sum([alpha * np.where(test_data[:, feature_idx] == 1, 1, -1)\n",
    "                                   for feature_idx, alpha in zip(range(X.shape[1]), [alpha])], axis=0))\n",
    "test_predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
